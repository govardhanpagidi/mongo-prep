GridFS is a specification for storing and retrieving files that exceed the BSON-document size limit of 16 MB.

GridFS does not support multi-document transactions.

Instead of storing a file in a single document, GridFS divides the file into parts, or chunks [1], and stores each chunk as a separate document. 

By default, GridFS uses a default chunk size of 255 kB; that is, GridFS divides a file into chunks of 255 kB with the exception of the last chunk. The last chunk is only as large as necessary. 

Similarly, files that are no larger than the chunk size only have a final chunk, using only as much space as needed plus some additional metadata.

GridFS uses two collections to store files. One collection stores the file chunks, and the other stores file metadata.

When you query GridFS for a file, the driver will reassemble the chunks as needed. You can perform range queries on files stored through GridFS. You can also access information from arbitrary sections of files, such as to "skip" to the middle of a video or audio file.

GridFS is useful not only for storing files that exceed 16 MB but also for storing any files for which you want access without having to load the entire file into memory.

When to use GridFS
-------------------------
In MongoDB, use GridFS for storing files larger than 16 MB.

In some situations, storing large files may be more efficient in a MongoDB database than on a system-level filesystem.
	- If your filesystem limits the number of files in a directory, you can use GridFS to store as many files as needed.
	- When you want to access information from portions of large files without having to load whole files into memory, you can use GridFS to recall sections of files without reading the entire file into memory.
	- When you want to keep your files and metadata automatically synced and deployed across a number of systems and facilities, you can use GridFS. When using geographically distributed replica sets, MongoDB can distribute files and their metadata automatically to a number of mongod instances and facilities.

Do not use GridFS if you need to update the content of the entire file atomically. 

As an alternative you can store multiple versions of each file and specify the current version of the file in the metadata. You can update the metadata field that indicates "latest" status in an atomic update after uploading the new version of the file, and later remove previous versions if needed.

Use GridFS
------------------
To store and retrieve files using GridFS, use either of the following:
	1. A MongoDB Driver.
	2. mongofiles command-line tool

GridFS stores files into two collections - 
	- chunks stores the binary chunks (fs.chunks)
	- files stores the file's metadata (fs.files)

Each document in the fs.chunks collection represent a distinct chunk of a file in the following form:
{
  "_id" : <ObjectId>,
  "files_id" : <ObjectId>,
  "n" : <num>,
  "data" : <binary>
}

_id - Unique ObjectId
files_id - _id of the parent document as specified in the files collection
n - Sequence number of the chunk, starting with 0.
data - Chunk's payload as a BSON binary type.

Each document in the files collection represents a file in GridFS.
{
  "_id" : <ObjectId>,
  "length" : <num>,
  "chunkSize" : <num>,
  "uploadDate" : <timestamp>,
  "md5" : <hash>,
  "filename" : <string>,
  "contentType" : <string>,
  "aliases" : <string array>,
  "metadata" : <any>,
}
_id - Unique Id
length - size of the document in bytes
chunkSize - size of each chunk in bytes
uploadDate - Date when the document was first stored by GridFS. Date type.
md5 - An MD5 hash of the complete file (Deprecated)
filename - Optional human readable filename
contentType - Mime Type (deprecated)
metadata - any data type

GridFS Indexes - Uses indexes on each of the chunks and files collections for efficiency. Drivers automatically create these indexes for convenience. You can also create any additional indexes as desired to suit app needs.

Chunks Index - Unique Compound index on files_id and n fields.

files index - Compound index on filename and uploadDate fields.

Sharding GridFS
-------------------
	To shard chunks collection, use compound index on files_id + n or files_id as the shard key index. files_id is an ObjectId and changes montonically.

	You can use Hashed Sharding for chunks collection if driver does not run filemd5 successfully to verify upload. If driver runs filemd5, you cannot use Hashed Sharding.

	files collection is small and contains only metadata. None of the required keys in the GridFS lend themselves to an even distribution in a sharded environment. Leaving files unsharded allows all the files metadata documents to live on the primary shard.

	If you must shard the files collection, use the _id field, possibly in combination with application field.

mongofiles
--------------
mongofiles <options> <connection-string> <command> <filename or _id>

options
	- help, verbose/v, quiet, version, config=<filename>, uri=<connectionString>, host=<hostname><:port>, authenticationDatabase=<dbname>, db=<database>, local=<name in local filesystem for get & put>, type=<MIME>, replace, prefix=<string, default is 'fs'>, writeConcern=<document>, readPreference=<String|document>

readPreference default is primary

command - 
	list <prefix>
	search <string>
	put <filename1[filename2]...>
	get <filename1[filename2]...>
	get_id "<_id>"
	get_regex <regex> --regexOptions <regex-options>
	delete <filename>
	delete_id "<_id>"

mongofiles -d=records list

mongofiles --port=37017 -d=records list
mongofiles --host=db1.example.net -d=records list
mongofiles --host=db1.example.net --port=37017 -d=records list

mongofiles -d=records put 32-corinth.lp
mongofiles -d=records delete 32-corinth.lp
mongofiles -d=records search corinth
mongofiles -d=records list 32
mongofiles -d=records get 32-corinth.lp
mongofiles -d=records get_regex 32*.lp
mongofiles -d=records get_id '{"$oid": "56feac751f417d0357e7140f"}'